{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16331,
     "status": "ok",
     "timestamp": 1542211687573,
     "user": {
      "displayName": "Prabhat Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-jYkvtZRQSZA/AAAAAAAAAAI/AAAAAAAABQk/AcdRqtjr1VQ/s64/photo.jpg",
      "userId": "06798402360737137591"
     },
     "user_tz": -330
    },
    "id": "xtzjQWHyK-e8",
    "outputId": "9cb81b9e-1637-49b1-b876-c50ab82c4415"
   },
   "outputs": [],
   "source": [
    "# # Uncomment this for using at Google Colab\n",
    "# !pip -q install nltk\n",
    "# !pip -q install torch\n",
    "# !pip -q install gensim\n",
    "# !pip -q install wordcloud\n",
    "# !pip -q install torchvision\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# path = \"gdrive/My Drive/AML/Project/Dataset/\"\n",
    "\n",
    "path = '/home/arpan_aml/Project/dataset/'\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "import _pickle as pickle\n",
    "import string\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import seaborn as sb\n",
    "from torch import nn\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgzZRgRNipvl"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmUl5tDgNrBb"
   },
   "source": [
    "### Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gngMqn7kLAKe"
   },
   "outputs": [],
   "source": [
    "with open(path+'dataset_lstm.pkl', 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "trainX = data['trainX']\n",
    "trainY = data['trainY']\n",
    "testX = data['testX']\n",
    "testY = data['testY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUBvnrfjipvs"
   },
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, dataX, dataY, transform=None):\n",
    "        dataX = np.resize(dataX, (dataX.shape[0], 1, dataX.shape[1]))\n",
    "        self.dataX = dataX\n",
    "        self.dataY = dataY\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataX)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataX[index], self.dataY[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKPp9o8Bipvu"
   },
   "outputs": [],
   "source": [
    "train_data = customDataset(trainX, trainY)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=False)\n",
    "\n",
    "test_data = customDataset(testX, testY)\n",
    "test_loader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Bxk_f1Eipvx"
   },
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=4, kernel_size=3, stride=1)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=4, out_channels=8, kernel_size=3, stride=1)\n",
    "#         self.fc1 = nn.Linear(2368, 1000)\n",
    "#         self.fc2 = nn.Linear(1000, 500)\n",
    "#         self.fc3 = nn.Linear(500, 150)\n",
    "#         self.fc4 = nn.Linear(300, 150)\n",
    "#         self.fc5 = nn.Linear(150, 50)\n",
    "#         self.fc6 = nn.Linear(50, 2)\n",
    "#         self.relu = nn.ReLU(True)\n",
    "#     def forward(self, X):\n",
    "#         X1, X2 = torch.split(X, 300, dim=2)\n",
    "#         X1 = self.relu(self.conv1(X1))\n",
    "#         X1 = self.relu(self.conv2(X1))\n",
    "#         X2 = self.relu(self.conv1(X2))\n",
    "#         X2 = self.relu(self.conv2(X2))\n",
    "        \n",
    "#         X1 = X1.view(X1.shape[0], -1)\n",
    "#         X2 = X2.view(X2.shape[0], -1)\n",
    "        \n",
    "#         X1 = self.relu(self.fc1(X1))\n",
    "#         X1 = self.relu(self.fc2(X1))\n",
    "#         X1 = self.relu(self.fc3(X1))\n",
    "#         X2 = self.relu(self.fc1(X2))\n",
    "#         X2 = self.relu(self.fc2(X2))\n",
    "#         X2 = self.relu(self.fc3(X2))\n",
    "\n",
    "#         X = torch.cat((X1, X2), dim=1)\n",
    "        \n",
    "#         X = self.relu(self.fc4(X))\n",
    "#         X = self.relu(self.fc5(X))\n",
    "#         X = self.relu(self.fc6(X))\n",
    "#         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wnx8B_f8nYl9"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=4, kernel_size=3, stride=1)\n",
    "        self.fc1 = nn.Linear(1192, 600)\n",
    "        self.fc2 = nn.Linear(600, 300)\n",
    "        self.fc3 = nn.Linear(300, 150)\n",
    "        self.fc4 = nn.Linear(300, 150)\n",
    "        self.fc5 = nn.Linear(150, 50)\n",
    "        self.fc6 = nn.Linear(50, 2)\n",
    "        self.relu = nn.ReLU(True)\n",
    "    def forward(self, X):\n",
    "        X1, X2 = torch.split(X, 300, dim=2)\n",
    "        X1 = self.relu(self.conv1(X1))\n",
    "        X2 = self.relu(self.conv1(X2))\n",
    "        \n",
    "        X1 = X1.view(X1.shape[0], -1)\n",
    "        X2 = X2.view(X2.shape[0], -1)\n",
    "        \n",
    "        X1 = self.relu(self.fc1(X1))\n",
    "        X1 = self.relu(self.fc2(X1))\n",
    "        X1 = self.relu(self.fc3(X1))\n",
    "        X2 = self.relu(self.fc1(X2))\n",
    "        X2 = self.relu(self.fc2(X2))\n",
    "        X2 = self.relu(self.fc3(X2))\n",
    "\n",
    "        X = torch.cat((X1, X2), dim=1)\n",
    "        \n",
    "        X = self.relu(self.fc4(X))\n",
    "        X = self.relu(self.fc5(X))\n",
    "        X = self.relu(self.fc6(X))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pharKwvB4Tjx"
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(426,300),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(300,100),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(100,50),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(50,25),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(25,10),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(10,2))\n",
    "   \n",
    "    def forward(self, X):\n",
    "         return self.fc(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLJLPaJ9ipvz"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(data_loader, model):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        X = Variable(X).to(device)\n",
    "        Y = Y.to(device)\n",
    "        outputs = model(X)\n",
    "#         print(outputs.size())\n",
    "        _, pred = torch.max(outputs.data, 2)\n",
    "        \n",
    "        total += Y.size(0)\n",
    "        pred = pred.view(pred.size(0),)\n",
    "#         print(pred.size(),Y.size())\n",
    "#         break\n",
    "        correct += int((pred == Y).sum())\n",
    "    accuracy = (100.0 * correct) / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 169560,
     "status": "error",
     "timestamp": 1542212604421,
     "user": {
      "displayName": "Prabhat Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-jYkvtZRQSZA/AAAAAAAAAAI/AAAAAAAABQk/AcdRqtjr1VQ/s64/photo.jpg",
      "userId": "06798402360737137591"
     },
     "user_tz": -330
    },
    "id": "hdkR11ACipv3",
    "outputId": "df6f5850-8888-4d81-beab-e95cb8e6e9ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arpan_aml/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/arpan_aml/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/arpan_aml/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.4175333709, Accuracy:69.4475000000\n",
      "epoch [2/100], loss:0.2587286095, Accuracy:69.6550000000\n",
      "epoch [3/100], loss:0.2956409342, Accuracy:70.3200000000\n",
      "epoch [4/100], loss:0.2534906585, Accuracy:70.0450000000\n",
      "epoch [5/100], loss:0.2102061744, Accuracy:70.4875000000\n",
      "epoch [6/100], loss:0.1863629899, Accuracy:70.7825000000\n",
      "epoch [7/100], loss:0.2104191242, Accuracy:70.8025000000\n",
      "epoch [8/100], loss:0.1678928161, Accuracy:70.9825000000\n",
      "epoch [9/100], loss:0.2166615519, Accuracy:71.1300000000\n",
      "epoch [10/100], loss:0.1604519437, Accuracy:70.9725000000\n",
      "epoch [11/100], loss:0.1933946103, Accuracy:71.3600000000\n",
      "epoch [12/100], loss:0.1474352592, Accuracy:70.9300000000\n",
      "epoch [13/100], loss:0.1250012053, Accuracy:71.4300000000\n",
      "epoch [14/100], loss:0.1389182103, Accuracy:71.2850000000\n",
      "epoch [15/100], loss:0.1701091322, Accuracy:71.2125000000\n",
      "epoch [16/100], loss:0.1353060086, Accuracy:71.2400000000\n",
      "epoch [17/100], loss:0.1346511712, Accuracy:71.4400000000\n",
      "epoch [18/100], loss:0.1329972727, Accuracy:71.3975000000\n",
      "epoch [19/100], loss:0.1397051389, Accuracy:71.1000000000\n",
      "epoch [20/100], loss:0.1334299364, Accuracy:71.4625000000\n",
      "epoch [21/100], loss:0.1600952630, Accuracy:71.5725000000\n",
      "epoch [22/100], loss:0.1853773646, Accuracy:71.4750000000\n",
      "epoch [23/100], loss:0.1093199817, Accuracy:71.3825000000\n",
      "epoch [24/100], loss:0.0348220477, Accuracy:71.2925000000\n",
      "epoch [25/100], loss:0.1642512408, Accuracy:71.3950000000\n",
      "epoch [26/100], loss:0.1609864862, Accuracy:69.9375000000\n",
      "epoch [27/100], loss:0.1825414504, Accuracy:71.3425000000\n",
      "epoch [28/100], loss:0.1630276566, Accuracy:71.6475000000\n",
      "epoch [29/100], loss:0.0601902508, Accuracy:71.2325000000\n",
      "epoch [30/100], loss:0.0617659644, Accuracy:71.4875000000\n",
      "epoch [31/100], loss:0.0247827684, Accuracy:71.4000000000\n",
      "epoch [32/100], loss:0.1380823808, Accuracy:70.6450000000\n",
      "epoch [33/100], loss:0.0651795050, Accuracy:71.3275000000\n",
      "epoch [34/100], loss:0.0677066346, Accuracy:71.3025000000\n",
      "epoch [35/100], loss:0.0499832901, Accuracy:71.3950000000\n",
      "epoch [36/100], loss:0.0657779934, Accuracy:71.2575000000\n",
      "epoch [37/100], loss:0.0136872306, Accuracy:70.7250000000\n",
      "epoch [38/100], loss:0.0341523010, Accuracy:71.1475000000\n",
      "epoch [39/100], loss:0.0566395239, Accuracy:71.4175000000\n",
      "epoch [40/100], loss:0.1741878798, Accuracy:71.3475000000\n",
      "epoch [41/100], loss:0.0501225808, Accuracy:71.1400000000\n",
      "epoch [42/100], loss:0.0380340742, Accuracy:71.4325000000\n",
      "epoch [43/100], loss:0.0342657970, Accuracy:70.6975000000\n",
      "epoch [44/100], loss:0.1402764613, Accuracy:71.3400000000\n",
      "epoch [45/100], loss:0.1017995618, Accuracy:71.2425000000\n",
      "epoch [46/100], loss:0.1613183345, Accuracy:68.8875000000\n",
      "epoch [47/100], loss:0.0340724589, Accuracy:71.1675000000\n",
      "epoch [48/100], loss:0.0490897944, Accuracy:70.7550000000\n",
      "epoch [49/100], loss:0.0577424769, Accuracy:70.8975000000\n",
      "epoch [50/100], loss:0.0756227827, Accuracy:70.7625000000\n",
      "epoch [51/100], loss:0.0411592598, Accuracy:71.2150000000\n",
      "epoch [52/100], loss:0.0681162516, Accuracy:71.2650000000\n",
      "epoch [53/100], loss:0.0470321868, Accuracy:71.0000000000\n",
      "epoch [54/100], loss:0.0641931371, Accuracy:71.0350000000\n",
      "epoch [55/100], loss:0.0833304669, Accuracy:71.1750000000\n",
      "epoch [56/100], loss:0.0353994325, Accuracy:71.2775000000\n",
      "epoch [57/100], loss:0.0345230266, Accuracy:71.0850000000\n",
      "epoch [58/100], loss:0.0316073603, Accuracy:71.0150000000\n",
      "epoch [59/100], loss:0.0321652865, Accuracy:71.2375000000\n",
      "epoch [60/100], loss:0.0455973335, Accuracy:71.2125000000\n",
      "epoch [61/100], loss:0.0316619376, Accuracy:70.6225000000\n",
      "epoch [62/100], loss:0.0422415328, Accuracy:71.1400000000\n",
      "epoch [63/100], loss:0.0319895137, Accuracy:70.7475000000\n",
      "epoch [64/100], loss:0.0443351034, Accuracy:70.9600000000\n",
      "epoch [65/100], loss:0.0295212465, Accuracy:70.5900000000\n",
      "epoch [66/100], loss:0.0312114619, Accuracy:71.1300000000\n",
      "epoch [67/100], loss:0.0336066398, Accuracy:70.9675000000\n",
      "epoch [68/100], loss:0.0319431824, Accuracy:70.9175000000\n",
      "epoch [69/100], loss:0.0325226732, Accuracy:70.5475000000\n",
      "epoch [70/100], loss:0.0304575385, Accuracy:70.7750000000\n",
      "epoch [71/100], loss:0.0295444402, Accuracy:71.1900000000\n",
      "epoch [72/100], loss:0.0300061105, Accuracy:70.6500000000\n",
      "epoch [73/100], loss:0.0324898684, Accuracy:70.7700000000\n",
      "epoch [74/100], loss:0.0296646376, Accuracy:70.3025000000\n",
      "epoch [75/100], loss:0.0278168357, Accuracy:70.3050000000\n",
      "epoch [76/100], loss:0.0290640803, Accuracy:69.7200000000\n",
      "epoch [77/100], loss:0.0278983727, Accuracy:71.1375000000\n",
      "epoch [78/100], loss:0.0291265953, Accuracy:70.5600000000\n",
      "epoch [79/100], loss:0.0283321820, Accuracy:70.6875000000\n",
      "epoch [80/100], loss:0.0395940979, Accuracy:71.0350000000\n",
      "epoch [81/100], loss:0.0304240342, Accuracy:71.1625000000\n",
      "epoch [82/100], loss:0.0277401085, Accuracy:69.6950000000\n",
      "epoch [83/100], loss:0.0286549404, Accuracy:70.8700000000\n",
      "epoch [84/100], loss:0.0309843096, Accuracy:70.7975000000\n",
      "epoch [85/100], loss:0.0380942418, Accuracy:70.9775000000\n",
      "epoch [86/100], loss:0.0316831898, Accuracy:70.9450000000\n",
      "epoch [87/100], loss:0.0352190468, Accuracy:70.6650000000\n",
      "epoch [88/100], loss:0.0365033044, Accuracy:71.1350000000\n",
      "epoch [89/100], loss:0.0301377362, Accuracy:71.1225000000\n",
      "epoch [90/100], loss:0.0281143778, Accuracy:71.0875000000\n",
      "epoch [91/100], loss:0.0286570131, Accuracy:70.8575000000\n",
      "epoch [92/100], loss:0.0290927831, Accuracy:70.8875000000\n",
      "epoch [93/100], loss:0.0285963676, Accuracy:70.9750000000\n",
      "epoch [94/100], loss:0.0283119798, Accuracy:70.9050000000\n",
      "epoch [95/100], loss:0.0312224440, Accuracy:70.5325000000\n",
      "epoch [96/100], loss:0.0795715026, Accuracy:70.2700000000\n",
      "epoch [97/100], loss:0.0401797266, Accuracy:70.8100000000\n",
      "epoch [98/100], loss:0.0769390222, Accuracy:70.7050000000\n",
      "epoch [99/100], loss:0.0310045990, Accuracy:70.9350000000\n",
      "epoch [100/100], loss:0.0374620282, Accuracy:70.8000000000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mdoel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-6b073006f3df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_accu'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_accu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdoel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'model_deep_network.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mdoel' is not defined"
     ]
    }
   ],
   "source": [
    "model = NN().to(device).double()\n",
    "\n",
    "model_data = {}\n",
    "optimizer = torch.optim.Adam(lr=0.001, params=model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss = []\n",
    "train_accu = []\n",
    "test_loss = []\n",
    "test_accu = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for X, Y in train_loader:\n",
    "        X = Variable(X).to(device)\n",
    "        Y = Variable(Y).to(device)\n",
    "        pred = model(X)\n",
    "        pred = pred.view(pred.shape[0],-1)\n",
    "        \n",
    "#         print(pred.shape, ' ', Y.shape)\n",
    "        loss = criterion(pred, Y)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss.append(loss.data[0])\n",
    "    train_accu.append(get_accuracy(train_loader, model))\n",
    "    test_accu.append(get_accuracy(test_loader, model))\n",
    "    print('epoch [{}/{}], loss:{:.10f}, Accuracy:{:.10f}'\n",
    "          .format(epoch + 1, n_epochs, loss.data[0], test_accu[-1]))\n",
    "\n",
    "    for X, Y in test_loader:\n",
    "        X = Variable(X).to(device)\n",
    "        Y = Variable(Y).to(device)\n",
    "        pred = model(X)\n",
    "        pred = pred.view(pred.shape[0],-1)\n",
    "        loss = criterion(pred, Y)\n",
    "        break\n",
    "    test_loss.append(loss.data[0])\n",
    "model_data['train_accu'] = train_accu\n",
    "model_data['train_loss'] = train_loss\n",
    "model_data['test_loss'] = test_loss\n",
    "model_data['test_accu'] = test_accu\n",
    "\n",
    "torch.save(mdoel, path+'model_deep_network.pt')\n",
    "with open(path + 'model_data.pkl', 'wb') as fp:\n",
    "    pickle.dump(model_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 965,
     "status": "ok",
     "timestamp": 1542212413806,
     "user": {
      "displayName": "Prabhat Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-jYkvtZRQSZA/AAAAAAAAAAI/AAAAAAAABQk/AcdRqtjr1VQ/s64/photo.jpg",
      "userId": "06798402360737137591"
     },
     "user_tz": -330
    },
    "id": "m76tFJsXipv_",
    "outputId": "3f0e6e46-9abc-4117-a468-abc19f2740c0"
   },
   "outputs": [],
   "source": [
    "get_accuracy(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    0.,     0.,     0.,  ...,  2827.,   328.,  2408.]],\n",
      "\n",
      "        [[    0.,     0.,     0.,  ...,     8.,    11.,    41.]],\n",
      "\n",
      "        [[    0.,     0.,     0.,  ...,   225., 29647.,  2023.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    0.,     0.,     0.,  ...,   376.,  2769.,     8.]],\n",
      "\n",
      "        [[    0.,     0.,     0.,  ...,   175.,  4062.,  3622.]],\n",
      "\n",
      "        [[    0.,     0.,     0.,  ...,  3361.,     3.,   154.]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for X, Y in train_loader:\n",
    "    X = Variable(X).to(device)\n",
    "    print((X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "solve_network.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
